{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1ère partie: Construction d'un modèle de Reconnaissance Automatique de la Parole (ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.2)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchaudio) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1->torchaudio) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1->torchaudio) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1->torchaudio) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch==2.0.1->torchaudio) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (0.58.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (4.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba>=0.51.0->librosa) (0.41.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pooch>=1.0->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pooch>=1.0->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.24.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration du modèle et de l'appareil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de l'appareil : cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-french\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Utilisation de l'appareil : {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du modèle et du processeur pré-entraînés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle et du processeur depuis jonatasgrosman/wav2vec2-large-xlsr-53-french...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "print(f\"Chargement du modèle et du processeur depuis {model_name}...\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour charger et prétraiter le fichier audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(file_path):\n",
    "    \"\"\"\n",
    "    Charge et prétraite un fichier audio en le rééchantillonnant à 16 kHz.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin vers le fichier audio à charger.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Tableau numpy contenant les données audio échantillonnées à 16 kHz.\n",
    "    \"\"\"\n",
    "    # Charger l'audio à 16 kHz\n",
    "    speech_array, _ = librosa.load(file_path, sr=16_000)\n",
    "    return speech_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour prédire la transcription de l'audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transcription(speech_array):\n",
    "    \"\"\"\n",
    "    Prédire la transcription à partir d'une séquence audio.\n",
    "\n",
    "    Args:\n",
    "        speech_array (numpy.ndarray): Tableau numpy contenant les données audio prétraitées.\n",
    "\n",
    "    Returns:\n",
    "        str: La transcription textuelle prédite pour l'audio fourni.\n",
    "    \"\"\"\n",
    "    # Préparer les inputs pour le modèle\n",
    "    inputs = processor(speech_array, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # Transférer les inputs sur le bon device (GPU ou CPU)\n",
    "    input_values = inputs.input_values.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    # Effectuer la prédiction sans gradient (inférence)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "\n",
    "    # Décoder les prédictions pour obtenir le texte transcrit\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(pred_ids)[0]\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcription l'audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: bonjour je suis content davoir étudié à did\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/USER/Documents/Audacity/dit.wav\"  \n",
    "speech_array = load_and_preprocess_audio(file_path)\n",
    "transcription = predict_transcription(speech_array)\n",
    "print(\"Transcription:\", transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ème Partie: Analyse de polarity sur la transcription générée par le modèle ASR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BarthezTokenizer, BartForSequenceClassification, AutoTokenizer\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition des classes du Dataset et du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllocineReviewsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file,\n",
    "        device,\n",
    "        model_name_or_path=\"moussaKam/barthez-sentiment-classification\",\n",
    "        max_length= 100\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.labels = self.df.polarity.unique()\n",
    "        labels_dict = dict()\n",
    "        for indx, l in enumerate(self.labels):\n",
    "            labels_dict[l] = indx\n",
    "        \n",
    "        self.df[\"polarity\"] = self.df[\"polarity\"].map(labels_dict)\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        review_text = self.df.review[index]\n",
    "        label_review = self.df.polarity[index]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            review_text,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = torch.tensor(label_review)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0).to(self.device),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0).to(self.device),\n",
    "            \"labels\": labels.to(self.device)\n",
    "        }\n",
    "    \n",
    "\n",
    "class SentimentAnalysisBart(nn.Module):\n",
    "    def __init__(self, model_name_or_path=\"moussaKam/barthez-sentiment-classification\", n_classes=2):\n",
    "        super(SentimentAnalysisBart, self).__init__()\n",
    "        self.bart_pretained = BartForSequenceClassification.from_pretrained(model_name_or_path, num_labels=n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x=self.bart_pretained(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in tqdm(train_loader, total=len(train_loader)):\n",
    "\n",
    "        input_ids = data[\"input_ids\"]\n",
    "        attention_mask = data[\"attention_mask\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_step(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    correct_predictions= 0\n",
    "    losses=[]\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, total=len(test_loader)):\n",
    "            input_ids = data[\"input_ids\"]\n",
    "            attention_mask = data[\"attention_mask\"]\n",
    "            labels = data[\"labels\"]\n",
    "\n",
    "            output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            _, pred = output.max(1)\n",
    "\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            correct_predictions += torch.sum(pred==labels)\n",
    "\n",
    "            loss = loss_fn(output, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "    return np.mean(losses) , correct_predictions /len(test_loader.dataset), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'analyse de sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(model, tokenizer, text, device):\n",
    "    \"\"\"\n",
    "    Analyse le sentiment d'une transcription textuelle.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle Bert pré-entraîné pour l'analyse de sentiment.\n",
    "        tokenizer: Tokenizer associé au modèle Bert.\n",
    "        text (str): La transcription textuelle dont le sentiment doit être analysé.\n",
    "        device (torch.device): L'appareil à utiliser pour l'inférence (CPU ou GPU).\n",
    "\n",
    "    Returns:\n",
    "        str: Le sentiment prédit (\"positive\" ou \"negative\").\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenisation du texte\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Préparer les inputs pour le modèle\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Effectuer la prédiction sans gradient (inférence)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Appliquer softmax pour obtenir les probabilités\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "    # Prendre l'index de la probabilité maximale pour obtenir la classe prédite\n",
    "    pred_class = torch.argmax(probs, dim=1).cpu().item()\n",
    "\n",
    "    # Mapper l'index de classe à une étiquette (positive/negative)\n",
    "    sentiment = \"positive\" if pred_class == 1 else \"negative\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "You are using a model of type mbart to instantiate a model of type bart. This is not supported for all configurations of models and can yield errors.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'Negative', '1': 'Positive'}. The number of labels wil be overwritten to 2.\n",
      "100%|██████████| 32/32 [05:19<00:00,  9.99s/it]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.07125017549842597 | Eval Loss : 0.700380265712738 | Accuracy : 0.42500001192092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:09<00:00,  9.66s/it]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.07003285996615886 | Eval Loss : 0.6869570165872574 | Accuracy : 0.574999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:18<00:00,  9.96s/it]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.06966057419776917 | Eval Loss : 0.6972134709358215 | Accuracy : 0.42500001192092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Transcription: bonjour je suis content davoir étudié à did\\nSentiment: positive'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    print(\"Training ...\")\n",
    "    N_EPOCHS = 3 \n",
    "    LR = 2e-5 \n",
    "    epsilon=1e-08\n",
    "    BATCH_SIZE = 10\n",
    "    MAX_LENGTH = 100\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = BarthezTokenizer.from_pretrained(\"moussaKam/barthez-sentiment-classification\")\n",
    "\n",
    "    train_dataset = AllocineReviewsDataset(csv_file=\"data-allocine-french-movie-reviews/train.csv\", device=device, max_length=MAX_LENGTH)\n",
    "    test_dataset = AllocineReviewsDataset(csv_file=\"data-allocine-french-movie-reviews/test.csv\", device=device, max_length=MAX_LENGTH)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = SentimentAnalysisBart()\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, eps=epsilon)\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        loss_train = training_step(model, train_loader, loss_fn, optimizer)\n",
    "        loss_eval, accuracy, all_preds, all_labels = evaluation_step(model, test_loader, loss_fn)\n",
    "\n",
    "\n",
    "        print(\n",
    "            f\"Train Loss : {loss_train} | Eval Loss : {loss_eval} | Accuracy : {accuracy}\"\n",
    "        )  \n",
    "\n",
    "\n",
    "    # Evaluation finale pour la matrice de confusion\n",
    "    loss_eval, accuracy, all_preds, all_labels = evaluation_step(model, test_loader, loss_fn)\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "    # sauvegarde model\n",
    "    torch.save(model.state_dict(), \"CarelBrian_ASR_Bart_SentimentAnalysis.pth\")\n",
    "\n",
    "    # Partie audio et transcription\n",
    "    file_path = \"C:/Users/USER/Documents/Audacity/dit.wav\"  \n",
    "    speech_array = load_and_preprocess_audio(file_path)\n",
    "    transcription = predict_transcription(speech_array)\n",
    "\n",
    "    # Analyse de sentiment sur la transcription\n",
    "    sentiment = analyze_sentiment(model, tokenizer, transcription, device)\n",
    "    display(f\"Transcription: {transcription}\\nSentiment: {sentiment}\")\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
